import os
import json
import requests
from typing import List, Dict, Any
from pathlib import Path

from elasticsearch import Elasticsearch
import openai
import numpy as np
import datetime

class SimpleRAGSystem:
    def __init__(self, 
                 es_host: str = "http://localhost:9200",
                 ollama_host: str = "http://localhost:11434",
                 embedding_model: str = "nomic-embed-text",
                 openai_api_key: str = "",
                 index_name: str = "rag_documents"):
        """
        ç®€åŒ–ç‰ˆRAGç³»ç»Ÿ - ä½¿ç”¨è¿œç¨‹OllamaåµŒå…¥æ¨¡å‹
        
        Args:
            es_host: ElasticsearchæœåŠ¡å™¨åœ°å€
            ollama_host: OllamaæœåŠ¡å™¨åœ°å€
            embedding_model: OllamaåµŒå…¥æ¨¡å‹åç§°
            openai_api_key: OpenAI APIå¯†é’¥
            index_name: Elasticsearchç´¢å¼•åç§°
        """
        # åˆå§‹åŒ–Elasticsearch
        self.es = es = Elasticsearch(
                        "http://117.50.27.204:1200", # ä½ çš„ Elasticsearch åœ°å€
                        basic_auth=("elastic", "infini_rag_flow"), # æ›¿æ¢ä¸ºä½ çš„ç”¨æˆ·åå’Œå¯†ç æˆ– API key
                        # æˆ–è€…ç”¨ Basic Auth
                        # basic_auth=("elastic", "your_password"),
                         verify_certs=False, # å¦‚æœæ˜¯æœ¬åœ°æµ‹è¯•ç¯å¢ƒä¸”æ²¡æœ‰æ­£ç¡®é…ç½® SSL è¯ä¹¦ï¼Œå¯ä»¥è®¾ç½®ä¸º False
                        ssl_show_warn=False
                    )
        self.index_name = index_name
        
        # åˆå§‹åŒ–Ollamaé…ç½®
        self.ollama_host = ollama_host.rstrip('/')
        self.embedding_model = embedding_model
        
        # æµ‹è¯•Ollamaè¿æ¥å¹¶è·å–æ¨¡å‹ä¿¡æ¯
        self.embedding_dim = self._init_ollama_embedding()
        
        # è®¾ç½®OpenAI
        # openai.api_key = openai_api_key
        
        # åˆ›å»ºç´¢å¼•
        self._create_index()
        
        print("RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
    
    def _init_ollama_embedding(self):
        """åˆå§‹åŒ–OllamaåµŒå…¥æ¨¡å‹å¹¶è·å–å‘é‡ç»´åº¦"""
        try:
            # æµ‹è¯•è¿æ¥
            response = requests.get(f"{self.ollama_host}/api/tags")
            if response.status_code != 200:
                raise Exception(f"æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡å™¨: {self.ollama_host}")
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            models = response.json().get('models', [])
            model_names = [model['name'].split(':')[0] for model in models]
            
            if self.embedding_model not in model_names:
                print(f"æ¨¡å‹ {self.embedding_model} ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ‹‰å–...")
                self._pull_model(self.embedding_model)
            
            # è·å–å‘é‡ç»´åº¦
            test_embedding = self._get_embedding("test")
            embedding_dim = len(test_embedding)
            
            print(f"Ollamaè¿æ¥æˆåŠŸ! ä½¿ç”¨æ¨¡å‹: {self.embedding_model}, å‘é‡ç»´åº¦: {embedding_dim}")
            return embedding_dim
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"Ollamaè¿æ¥å¤±è´¥: {e}")
        except Exception as e:
            raise Exception(f"åˆå§‹åŒ–OllamaåµŒå…¥æ¨¡å‹å¤±è´¥: {e}")
    
    def _pull_model(self, model_name: str):
        """æ‹‰å–Ollamaæ¨¡å‹"""
        try:
            print(f"æ­£åœ¨æ‹‰å–æ¨¡å‹ {model_name}ï¼Œè¯·ç¨å€™...")
            response = requests.post(
                f"{self.ollama_host}/api/pull",
                json={"name": model_name},
                stream=True
            )
            
            for line in response.iter_lines():
                if line:
                    data = json.loads(line.decode('utf-8'))
                    if 'status' in data:
                        print(f"æ‹‰å–çŠ¶æ€: {data['status']}")
                    if data.get('status') == 'success':
                        print(f"æ¨¡å‹ {model_name} æ‹‰å–æˆåŠŸ!")
                        break
        except Exception as e:
            raise Exception(f"æ‹‰å–æ¨¡å‹å¤±è´¥: {e}")
    
    def _get_embedding(self, text: str) -> List[float]:
        """ä½¿ç”¨Ollamaè·å–æ–‡æœ¬åµŒå…¥å‘é‡"""
        try:
            response = requests.post(
                f"{self.ollama_host}/api/embeddings",
                json={
                    "model": self.embedding_model,
                    "prompt": text
                },
                timeout=30
            )
            print(f'------{response}')
            if response.status_code != 200:
                raise Exception(f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            
            result = response.json()
            return result['embedding']
            
        except requests.exceptions.Timeout:
            raise Exception("Ollama APIè°ƒç”¨è¶…æ—¶")
        except Exception as e:
            raise Exception(f"è·å–åµŒå…¥å‘é‡å¤±è´¥: {e}")
    
    def _create_index(self):
        """åˆ›å»ºElasticsearchç´¢å¼•"""
        mapping = {
            "mappings": {
                "properties": {
                    "content": {"type": "text"},
                    "embedding": {
                        "type": "dense_vector",
                        "dims": self.embedding_dim
                    },
                    "source": {"type": "keyword"},
                    "timestamp": {"type": "date"}
                }
            }
        }
        
        # å¦‚æœç´¢å¼•ä¸å­˜åœ¨åˆ™åˆ›å»º
        if not self.es.indices.exists(index=self.index_name):
            self.es.indices.create(index=self.index_name, body=mapping)
            print(f"åˆ›å»ºç´¢å¼•: {self.index_name}")
    
    def add_text(self, text: str, source: str = "manual_input") -> str:
        """æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“"""
        try:
            # æ–‡æœ¬åˆ†å—
            chunks = self._split_text(text)
            
            added_count = 0
            for i, chunk in enumerate(chunks):
                if len(chunk.strip()) < 10:  # è·³è¿‡å¤ªçŸ­çš„å—
                    continue
                
                print(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} ä¸ªæ–‡æœ¬å—...")
                
                # ä½¿ç”¨Ollamaç”ŸæˆåµŒå…¥å‘é‡
                embedding = self._get_embedding(chunk)
                
                # å­˜å‚¨åˆ°ES
                doc = {
                    "content": chunk,
                    "embedding": embedding,
                    "source": f"{source}_chunk_{i}",
                    "timestamp":  datetime.datetime.now()
                }
                
                self.es.index(index=self.index_name, body=doc)
                added_count += 1
            
            self.es.indices.refresh(index=self.index_name)
            return f"æˆåŠŸæ·»åŠ  {added_count} ä¸ªæ–‡æœ¬å—åˆ°çŸ¥è¯†åº“"
            
        except Exception as e:
            return f"æ·»åŠ æ–‡æœ¬æ—¶å‡ºé”™: {str(e)}"
    
    def add_document(self, file_path: str) -> str:
        """æ·»åŠ æœ¬åœ°æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        try:
            file_path = Path(file_path)
            if not file_path.exists():
                return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = self._read_file(file_path)
            if not content:
                return f"æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {file_path}"
            
            # æ·»åŠ åˆ°çŸ¥è¯†åº“
            result = self.add_text(content, source=file_path.name)
            return f"æ–‡æ¡£ {file_path.name}: {result}"
            
        except Exception as e:
            return f"æ·»åŠ æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}"
    
    def _read_file(self, file_path: Path) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            suffix = file_path.suffix.lower()
            
            if suffix in ['.txt', '.md', '.py', '.js', '.html', '.css']:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return f.read()
            elif suffix == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return json.dumps(data, indent=2, ensure_ascii=False)
            else:
                print(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}")
                return ""
                
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
            return ""
    
    def _split_text(self, text: str, chunk_size: int = 500) -> List[str]:
        """ç®€å•çš„æ–‡æœ¬åˆ†å—"""
        # æŒ‰å¥å­åˆ†å‰²
        sentences = text.replace('\n\n', '\n').split('ã€‚')
        
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°å¥å­ä¸è¶…è¿‡é™åˆ¶ï¼Œå°±æ·»åŠ 
            if len(current_chunk + sentence) < chunk_size:
                current_chunk += sentence + "ã€‚"
            else:
                # å¦åˆ™ä¿å­˜å½“å‰å—ï¼Œå¼€å§‹æ–°å—
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = sentence + "ã€‚"
        
        # æ·»åŠ æœ€åä¸€å—
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """æœç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            print(f"æ­£åœ¨æœç´¢: {query}")
            
            # ä½¿ç”¨Ollamaç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self._get_embedding(query)
            
            # ESå‘é‡æœç´¢
            search_body = {
                "query": {
                    "script_score": {
                        "query": {"match_all": {}},
                        "script": {
                            "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
                            "params": {"query_vector": query_embedding}
                        }
                    }
                },
                "size": top_k
            }
            
            response = self.es.search(index=self.index_name, body=search_body)
            
            results = []
            for hit in response['hits']['hits']:
                results.append({
                    'content': hit['_source']['content'],
                    'source': hit['_source']['source'],
                    'score': hit['_score']
                })
            
            return results
            
        except Exception as e:
            print(f"æœç´¢æ—¶å‡ºé”™: {e}")
            return []
    
    def chat(self, question: str) -> str:
        """ä¸æ™ºèƒ½ä½“å¯¹è¯"""
        try:
            # æœç´¢ç›¸å…³å†…å®¹
            search_results = self.search(question, top_k=3)
            
            if not search_results:
                return "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = "\n\n".join([
                f"æ–‡æ¡£ç‰‡æ®µ {i+1} (æ¥æº: {result['source']}, ç›¸ä¼¼åº¦: {result['score']:.3f}):\n{result['content']}"
                for i, result in enumerate(search_results)
            ])
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

é—®é¢˜: {question}

è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”:"""
            
            # è°ƒç”¨OpenAI API
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œä¼šåŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500, 
                
                temperature=0.1
            )
            
            answer = response.choices[0].message.content
            
            # æ·»åŠ æ¥æºä¿¡æ¯
            sources = list(set([result['source'] for result in search_results]))
            source_info = f"\n\nğŸ“š å‚è€ƒæ¥æº: {', '.join(sources[:3])}"
            similarity_info = f"\nğŸ” æœ€é«˜ç›¸ä¼¼åº¦: {search_results[0]['score']:.3f}"
            
            return answer + source_info + similarity_info
            
        except Exception as e:
            return f"å¯¹è¯æ—¶å‡ºé”™: {str(e)}"
    
    def chat_with_ollama(self, question: str, chat_model: str = "bge-m3") -> str:
        """ä½¿ç”¨Ollamaè¿›è¡Œå¯¹è¯ (å¯é€‰åŠŸèƒ½)"""
        try:
            # æœç´¢ç›¸å…³å†…å®¹
            search_results = self.search(question, top_k=3)
            
            if not search_results:
                return "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = "\n\n".join([
                f"æ–‡æ¡£ç‰‡æ®µ {i+1}:\n{result['content']}"
                for i, result in enumerate(search_results)
            ])
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š
                    ä¸Šä¸‹æ–‡ä¿¡æ¯:
                    {context}
                    é—®é¢˜: {question}
                    è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”:
                    """
            
            # è°ƒç”¨Ollama API
            response = requests.post(
                f"{self.ollama_host}/api/embeddings",
                json={
                    "model": chat_model,
                    "prompt": prompt
                },
                timeout=60
            )
            print(response)
            if response.status_code == 200:
                result = response.json()
                answer = result.get('response', 'æ— æ³•è·å–å›ç­”')
            else:
                answer = f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}"
            
            # æ·»åŠ æ¥æºä¿¡æ¯
            sources = list(set([result['source'] for result in search_results]))
            source_info = f"\n\nğŸ“š å‚è€ƒæ¥æº: {', '.join(sources[:3])}"
            
            return answer + source_info
            
        except Exception as e:
            return f"ä½¿ç”¨Ollamaå¯¹è¯æ—¶å‡ºé”™: {str(e)}"
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–æ–‡æ¡£æ€»æ•°
            count_response = self.es.count(index=self.index_name)
            total_docs = count_response['count']
            
            # è·å–ç´¢å¼•ä¿¡æ¯
            index_info = self.es.indices.stats(index=self.index_name)
            index_size = index_info['indices'][self.index_name]['total']['store']['size_in_bytes']
            
            return {
                "total_documents": total_docs,
                "index_size_mb": round(index_size / (1024 * 1024), 2),
                "index_name": self.index_name,
                "embedding_model": self.embedding_model,
                "embedding_dimension": self.embedding_dim,
                "ollama_host": self.ollama_host
            }
            
        except Exception as e:
            return {"error": f"è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"}
    
    def clear_index(self):
        """æ¸…ç©ºçŸ¥è¯†åº“"""
        try:
            self.es.indices.delete(index=self.index_name)
            self._create_index()
            return "çŸ¥è¯†åº“å·²æ¸…ç©º"
        except Exception as e:
            return f"æ¸…ç©ºçŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}"
    
    def test_ollama_connection(self) -> str:
        """æµ‹è¯•Ollamaè¿æ¥"""
        try:
            response = requests.get(f"{self.ollama_host}/api/tags")
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_list = [model['name'] for model in models]
                return f"Ollamaè¿æ¥æ­£å¸¸! å¯ç”¨æ¨¡å‹: {model_list}"
            else:
                return f"Ollamaè¿æ¥å¤±è´¥: HTTP {response.status_code}"
        except Exception as e:
            return f"Ollamaè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"


# ä½¿ç”¨ç¤ºä¾‹å’Œä¸»ç¨‹åº
def main():
    print("=== RAGç³»ç»Ÿ - ä½¿ç”¨è¿œç¨‹OllamaåµŒå…¥æ¨¡å‹ ===")
    print("è¯·ç¡®ä¿ä»¥ä¸‹æœåŠ¡å·²å¯åŠ¨:")
    print("1. Elasticsearch (é»˜è®¤: http://localhost:9200)")
    print("2. Ollama (é»˜è®¤: http://localhost:11434)")
    
    # é…ç½®
    ES_HOST = "http://117.50.27.204:1200"
    OLLAMA_HOST = "http://117.50.27.204:11435"  # å¯ä»¥æ˜¯è¿œç¨‹åœ°å€ï¼Œå¦‚ "http://192.168.1.100:11434"
    EMBEDDING_MODEL = "bge-m3"    # æˆ–å…¶ä»–åµŒå…¥æ¨¡å‹å¦‚ "mxbai-embed-large"
    # OPENAI_API_KEY = ""  # æ›¿æ¢ä¸ºä½ çš„APIå¯†é’¥
    
    try:
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        rag = SimpleRAGSystem(
            es_host=ES_HOST,
            ollama_host=OLLAMA_HOST,
            embedding_model=EMBEDDING_MODEL,
            # openai_api_key=OPENAI_API_KEY
        )
        
        print("\nå‘½ä»¤è¯´æ˜:")
        print("- add: æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“")
        print("- file: æ·»åŠ æœ¬åœ°æ–‡ä»¶åˆ°çŸ¥è¯†åº“")
        print("- test: æµ‹è¯•Ollamaè¿æ¥")
        print("- stats: æŸ¥çœ‹çŸ¥è¯†åº“ç»Ÿè®¡")
        print("- clear: æ¸…ç©ºçŸ¥è¯†åº“")
        print("- ollama: ä½¿ç”¨Ollamaæ¨¡å‹å¯¹è¯")
        print("- quit: é€€å‡ºç¨‹åº")
        print("- æˆ–è€…ç›´æ¥è¾“å…¥é—®é¢˜ä¸AIå¯¹è¯")
        print("-" * 50)
        
        while True:
            user_input = input("\nè¯·è¾“å…¥: ").strip()
            
            if user_input.lower() == 'quit':
                break
            elif user_input.lower() == 'add':
                text = input("è¯·è¾“å…¥è¦æ·»åŠ çš„æ–‡æœ¬: ")
                result = rag.add_text(text)
                print(f"ç»“æœ: {result}")
            elif user_input.lower() == 'file':
                file_path = input("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„: ")
                result = rag.add_document(file_path)
                print(f"ç»“æœ: {result}")
            elif user_input.lower() == 'test':
                result = rag.test_ollama_connection()
                print(f"è¿æ¥æµ‹è¯•: {result}")
            elif user_input.lower() == 'stats':
                stats = rag.get_stats()
                print(f"çŸ¥è¯†åº“ç»Ÿè®¡: {stats}")
            elif user_input.lower() == 'clear':
                result = rag.clear_index()
                print(f"ç»“æœ: {result}")
            elif user_input.lower() == 'ollama':
                question = input("è¯·è¾“å…¥é—®é¢˜ (ä½¿ç”¨Ollamaå›ç­”): ")
                print("Ollamaæ­£åœ¨æ€è€ƒ...")
                answer = rag.chat_with_ollama(chat_model=EMBEDDING_MODEL,question=question)
                print(f"\nOllamaå›ç­”:\n{answer}")
            elif user_input:
                # ä¸AIå¯¹è¯
                print("AIæ­£åœ¨æ€è€ƒ...")
                answer = rag.chat(user_input)
                print(f"\nAIå›ç­”:\n{answer}")
    
    except Exception as e:
        print(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥:")
        print("1. Elasticsearchæ˜¯å¦å·²å¯åŠ¨")
        print("2. OllamaæœåŠ¡æ˜¯å¦å·²å¯åŠ¨")
        print("3. åµŒå…¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½")
        print("4. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")

if __name__ == "__main__":
    main()


# # é…ç½®ç¤ºä¾‹æ–‡ä»¶
# def create_config_example():
#     """åˆ›å»ºé…ç½®ç¤ºä¾‹æ–‡ä»¶"""
#     config = {
#         "es_host": "http://localhost:9200",
#         "ollama_host": "http://localhost:11434",  # å¯æ”¹ä¸ºè¿œç¨‹åœ°å€
#         "embedding_model": "nomic-embed-text",
#         "chat_model": "llama3.1",
#         "openai_api_key": "your-openai-api-key-here",
#         "index_name": "rag_documents"
#     }
    
#     with open("rag_config.json", "w", encoding="utf-8") as f:
#         json.dump(config, f, indent=2, ensure_ascii=False)
    
#     print("é…ç½®ç¤ºä¾‹æ–‡ä»¶å·²åˆ›å»º: rag_config.json")

# å–æ¶ˆæ³¨é‡Šä»¥åˆ›å»ºé…ç½®æ–‡ä»¶
# create_config_example()